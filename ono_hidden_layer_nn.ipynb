{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ono_hidden_layer_nn.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNuI72nFJ17rF4l9woNkozj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/2-Hidden-Layer-Neural-Networks/blob/master/ono_hidden_layer_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g7RkLBhjKMd"
      },
      "source": [
        "!pip install playground-data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h44hV9oei-Lz"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import plygdata as pg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bJqibRPkIOe"
      },
      "source": [
        "data = pg.dataset.DataGenerator.classify_xor(1000,noise=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLQrpTlzFVeo"
      },
      "source": [
        "df = pd.DataFrame(data).head()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA9up9pg12x1"
      },
      "source": [
        "#Seperate the data as train set and test set with 0.2\n",
        "X_train, y_train, X_test, y_test = pg.split_data(data, validation_size=0.2)\n",
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLDh_QrRMrSC"
      },
      "source": [
        "#Change the value of -1 in y_train and y_test with 0\n",
        "y_train = np.array([0 if y_train[i,0]==-1 else 1 for i in range(len(y_train))])\n",
        "y_train = y_train.reshape(800,1)\n",
        "y_test = np.array([0 if y_test[i,0]==-1 else 1 for i in range(len(y_test))])\n",
        "y_test = y_test.reshape(200,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1gYt0OyDtMm"
      },
      "source": [
        "X_train = X_train.T\n",
        "y_train = y_train.T\n",
        "X_test = X_test.T\n",
        "y_test = y_test.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGM-0p1Jspkl"
      },
      "source": [
        "print(\"Shape of X_train:\", X_train.shape,\n",
        "      \"\\nShape of y_train:\", y_train.shape,\n",
        "      \"\\nShape of X_test:\", X_test.shape,\n",
        "      \"\\nShape of y_test:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "986vWPFwEn8W"
      },
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "for i in range(X_train.shape[1]):\n",
        "  if y_train[0,i]==1:\n",
        "    plt.scatter(X_train[0,i], X_train[1,i] , c='#0877bd' , alpha=0.5)\n",
        "  else:\n",
        "    plt.scatter(X_train[0,i], X_train[1,i] , c='#f59322' , alpha=0.5)\n",
        "\n",
        "for i in range(X_test.shape[1]):\n",
        "  if y_test[0,i]==1:\n",
        "    plt.scatter(X_test[0,i], X_test[1,i] , c='#0877bd', edgecolors='#e8eaeb', s=80)\n",
        "  else:\n",
        "    plt.scatter(X_test[0,i], X_test[1,i] , c='#f59322', edgecolors='#e8eaeb' , s=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7ti96uncvLP"
      },
      "source": [
        "def initialization_parameters(x, y, num_node):\n",
        "  W1 = np.random.randn(num_node, x.shape[0]) * 0.001\n",
        "  b1 = np.zeros((num_node,1))\n",
        "\n",
        "  W2 = np.random.randn(y.shape[0],num_node) * 0.001\n",
        "  b2 = np.zeros((y.shape[0],1))\n",
        "\n",
        "  assert W1.shape == (num_node,x.shape[0])\n",
        "  assert b1.shape == (num_node, 1)\n",
        "\n",
        "  assert W2.shape == (y.shape[0], num_node)\n",
        "  assert b2.shape == (y.shape[0], 1)\n",
        "\n",
        "  parameters = {'W1':W1,\n",
        "                'b1':b1,\n",
        "                'W2':W2,\n",
        "                'b2':b2}\n",
        "  return parameters\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "def reluDerivative(x):\n",
        "  x[x<=0] = 0\n",
        "  x[x>0] = 1\n",
        "  return x\n",
        "\n",
        "def forward_prop(x,parameters):\n",
        "  W1 = parameters['W1']\n",
        "  b1 = parameters['b1']\n",
        "  W2 = parameters['W2']\n",
        "  b2 = parameters['b2']\n",
        "  \n",
        "  Z1 = np.dot(W1, x) + b1\n",
        "  A1 = relu(Z1)\n",
        "  Z2 = np.dot(W2, A1) + b2\n",
        "  A2 = sigmoid(Z2)\n",
        "\n",
        "  assert (A2.shape == (1, x.shape[1]))\n",
        "  cache = {\n",
        "      'Z1' : Z1,\n",
        "      'A1' : A1,\n",
        "      'Z2' : Z2,\n",
        "      'A2' : A2\n",
        "  }\n",
        "  return A2, cache\n",
        "\n",
        "def backward_prop(x, y, parameters, cache, learning_rate = 0.1):\n",
        "  m = y.shape[1]\n",
        "  \n",
        "  W1 = parameters['W1']\n",
        "  b1 = parameters['b1']\n",
        "  W2 = parameters['W2']\n",
        "  b2 = parameters['b2']\n",
        "\n",
        "  A1 = cache['A1']\n",
        "  A2 = cache['A2']\n",
        "  Z1 = cache['Z1']\n",
        "  \n",
        "  # Calculations of backward propagation: dW1, db1, dW2, db2\n",
        "  dZ2 = A2 - y\n",
        "  dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
        "  db2 = (1 / m) * np.sum(dZ2, axis = 1, keepdims = True)\n",
        "\n",
        "  dZ1 = np.multiply(np.dot(W2.T, dZ2), reluDerivative(Z1))\n",
        "  dW1 = (1 / m) * np.dot(dZ1, x.T)\n",
        "  db1 = (1 / m) * np.sum(dZ1 , axis = 1, keepdims = True)\n",
        "\n",
        "  # Updating parameters\n",
        "  W1 = W1 - learning_rate * dW1\n",
        "  b1 = b1 - learning_rate * db1\n",
        "  W2 = W2 - learning_rate * dW2\n",
        "  b2 = b2 - learning_rate * db2\n",
        "  \n",
        "  parameters = {'W1':W1,\n",
        "                'b1':b1,\n",
        "                'W2':W2,\n",
        "                'b2':b2}\n",
        "  return parameters\n",
        "\n",
        "def cross_entropy_cost(y, A2):\n",
        "  m = y.shape[1]\n",
        "  \n",
        "  cross_entropy = np.multiply(np.log(A2 + 1e-15), y) + np.multiply((1 - y), np.log(1 - A2 + 1e-15))\n",
        "  cost = - 1.0 / m * np.sum(cross_entropy)\n",
        "\n",
        "  # Squeezing to avoid unnecessary dimensions \n",
        "  cost = np.squeeze(cost) \n",
        "  return cost  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW-TtsXb3miY"
      },
      "source": [
        "def nn_model(x, y, parameters, number_of_iter = 1000):\n",
        "  cost_value = {}\n",
        "  A2, cache = forward_prop(x, parameters)\n",
        "  cost = cross_entropy_cost(y, A2)\n",
        "  cost_value[1] = cost\n",
        "\n",
        "  for i in range(1,number_of_iter):\n",
        "    parameters = backward_prop(x, y, parameters, cache, learning_rate=0.1)\n",
        "    A2, cache = forward_prop(x, parameters)\n",
        "    cost = cross_entropy_cost(y, A2)\n",
        "    \n",
        "    #cost_value[i+1] = cost\n",
        "    \n",
        "    if (i+1) % 100 == 0:\n",
        "     cost_value[i+1] = cost\n",
        "     print(\"%i.\"%(i+1),cost)\n",
        "  return cost_value, parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOT2wi9XLSYd"
      },
      "source": [
        "#np.random.seed(0)\n",
        "parameters = initialization_parameters(X_test, y_test, 20)\n",
        "cost_value, parameters = nn_model(X_train, y_train, parameters, number_of_iter = 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P9kce6YN1FI"
      },
      "source": [
        "print(cost_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9ONZyZhARBg"
      },
      "source": [
        "clor= [pg.DataColor.get_rgb(i) for i in range(-1,2)]\n",
        "clor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2tw1trgXZZo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}